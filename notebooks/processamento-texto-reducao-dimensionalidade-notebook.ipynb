{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento de Texto e Redução de Dimensionalidade com Feature Hashing\n",
    "\n",
    "## Analise de Algoritmos e Estruturas de Dados - Profa. Lilian Berton\n",
    "@author: Willian Dihanster Gomes de Oliveira\n",
    "\n",
    "Referencias:\n",
    " - https://kavita-ganesan.com/hashingvectorizer-vs-countvectorizer/#.YLAX7qhKjIV\n",
    " - https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Imports e Leitura do Dataset\n",
    "Aqui faremos os imports e leitura dos dataset, que é esta disponível diretamente no sklearn que textos sobre diversos assuntos. No caso, será selecionado um subset balanceado de treino e teste com textos sobre 'eletronics' e 'space'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['sci.electronics', 'sci.space']\n",
    "\n",
    "train = fetch_20newsgroups(\n",
    "    subset='train', \n",
    "    categories=categories,\n",
    "    remove=('headers', 'footers', 'quotes')\n",
    ")\n",
    "test = fetch_20newsgroups(\n",
    "    subset='test',\n",
    "    categories=categories,\n",
    "    remove=('headers', 'footers', 'quotes')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1- Exemplo de texto sobre 'eletronics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nCan I suggest the University of Western Australia in Perth.\\nThe weathers great, the people are great and our Electronic Engineering department is great.\\nI am a first year student here ... so I don't know much about what projects but I do know they have a good reputation in the fields of dsp and communications.  Ever heard of QPSX?  The people who own are ex-UWA ... so that gives an indication of what the department is like.\\n\\nFor more information\\nemail: yianni@swanee.ee.uwa.edu.au\\nwith the above request and he should be able to tell some more info\\n\\nor write\\n\\nDepartment of Electrical and Electronic Engineering\\nUniversity of Western Australia\\nStirling Highway\\nCRAWLEY 6009\\nWestern Australia\\nAustralia\\n\\n\\nYours\\nMark\\n\\nmtearle@tartarus.uwa.edu.au\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Exemplo de texto sobre 'space'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[Excellent discussion of DC-X landing techniques by Henry deleted]\\n\\n\\nThe DC-X will not take of horizontally.  It takes of vertically. \\n\\n\\nFor several reasons.  Vertical landings don\\'t require miles of runway and limit\\nnoise pollution.  They don\\'t require wheels or wings.  Just turn on the engines\\nand touch down.  Of course, as Henry pointed out, vetical landings aren\\'t quite\\nthat simple.\\n\\n\\nWell, to be blunt, yes.  But at least you\\'re learning.\\n\\n\\nThe Soyuz vehicles use parachutes for the descent and then fire small rockets\\njust before they hit the ground.  Parachutes are, however, not especially\\npractical if you want to reuse something without much effort.  The landings\\nare also not very comfortable.  However, in the words of Georgy Grechko,\\n\"I prefer to have bruises, not to sink.\"\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Aplicação do HashingVectorizer\n",
    "Aqui faremos a aplicação do HashingVectorizer. Note que o principal parâmetro aqui é N, o valor que consideraremos para o tamanho do nosso espaço de features. Podemos definir qualquer valor, porém, levando em conta que valores muito pequenos, possivelmente gerará mais colisões e com isso, mais erros.\n",
    "\n",
    "Além disso, executaremos um total de 10 vezes e tiraremos a média do tempo gasto, e algumas métricas finais para comparação dos métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79       393\n",
      "           1       0.76      0.88      0.82       394\n",
      "\n",
      "    accuracy                           0.80       787\n",
      "   macro avg       0.81      0.80      0.80       787\n",
      "weighted avg       0.81      0.80      0.80       787\n",
      "\n",
      "Tempo medio com o HashingVectorizer = 0.257513380050659s\n"
     ]
    }
   ],
   "source": [
    "tempos = []\n",
    "N = 1000\n",
    "\n",
    "for i in range(10):\n",
    "    inicio = time.time()\n",
    "    \n",
    "    # Inicia o vectorizer\n",
    "    vectorizer = HashingVectorizer(n_features=N, alternate_sign=False)\n",
    "    \n",
    "    # Aplica o vectorizer no dataset de treino e teste\n",
    "    X_train = vectorizer.fit_transform(train.data)\n",
    "    y_train = train.target\n",
    "    \n",
    "    X_test = vectorizer.transform(test.data)\n",
    "    y_test = test.target\n",
    "    \n",
    "    # Inicia e treina o classificador Multinomial Naive Bayes\n",
    "    clf = MultinomialNB(alpha=.01)\n",
    "    clf.fit(X_train, y_train)\n",
    "    MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
    "    \n",
    "    # Faz as predicoes\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Salva o tempo gasto nesta iteracao\n",
    "    fim = time.time()\n",
    "    tempos.append(fim-inicio)\n",
    "\n",
    "# Printa o ultim o resultado da Classificacao e o tempo medio gasto\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Tempo medio com o HashingVectorizer = {round(sum(tempos)/len(tempos), 15)}s')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Aplicação do CountingVectorizer\n",
    "Aqui faremos o uso do algoritmo CountingVectorizer, seguindo a mesma ideia de execução e avaliação do algoritmo anterior. Note que também podemos definir o valor de N, que definir o máximo de colunas utilizadas, porém, o algoritmo ainda sim irá calcular todo o dicionário de palavras e então considerar as N mais populares, o que pode levar mais tempo que o método anterior mesmo com N igual ou menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91       393\n",
      "           1       0.88      0.95      0.92       394\n",
      "\n",
      "    accuracy                           0.91       787\n",
      "   macro avg       0.91      0.91      0.91       787\n",
      "weighted avg       0.91      0.91      0.91       787\n",
      "\n",
      "Tempo medio com o CountVectorizer = 0.38299834728241s\n"
     ]
    }
   ],
   "source": [
    "tempos = []\n",
    "N = None\n",
    "\n",
    "for i in range(10):\n",
    "    inicio = time.time()\n",
    "\n",
    "    # Inicia o vectorizer\n",
    "    vectorizer = CountVectorizer(max_features=N)\n",
    "\n",
    "    # Aplica o vectorizer no dataset de treino e teste\n",
    "    X_train = vectorizer.fit_transform(train.data)\n",
    "    y_train = train.target\n",
    "    \n",
    "    X_test = vectorizer.transform(test.data)\n",
    "    y_test = test.target\n",
    "    \n",
    "    # Inicia e treina o classificador Multinomial Naive Bayes\n",
    "    clf = MultinomialNB(alpha=.01)\n",
    "    clf.fit(X_train, y_train)\n",
    "    MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
    "    \n",
    "    # Faz as predicoes\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Salva o tempo gasto nesta iteracao\n",
    "    fim = time.time()\n",
    "    tempos.append(fim-inicio)\n",
    "\n",
    "# Printa o ultim o resultado da Classificacao e o tempo medio gasto\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Tempo medio com o CountVectorizer = {round(sum(tempos)/len(tempos), 15)}s')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Conclusões\n",
    "Hashing Vectorizer pode ser uma boa opção quando a prioridade é tempo e/ou menos gastos de memória, e é aceitável colisões/errar mais e quando não é necessário sabermos as palavras utilizadas. <br>\n",
    "Counting Vectorizer pode ser mais indicado quando se busca melhores resultados (em termos de acurácia) e/ou se saber qual palavra foi utilizada será útil, além de ser possível aceitar o tempo maior e o uso de memória a mais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
